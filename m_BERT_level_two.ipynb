{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8Im0bTY270Z"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MI2yteE_1_1V",
        "outputId": "514cc6b6-7003-4930-f21a-7fa5e9c8b767"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text Category\n",
              "0  তোমাদের মেধা নেই বলে মডেল হতে পারছো না, নিজেদে...    coRAC\n",
              "1      ওই ফকিরের কালো পোলা আমাদের সাথে খেতে পারবে না    coRAC\n",
              "2  আমি একজন বর্ণবাদী হয়ে জন্মেছি এবং আমি একজন বর...    coRAC\n",
              "3                     দুশ্চরিত্রা নিগা আমাকে মিস করে    coRAC\n",
              "4  যদি আপনি সেই খুনের খেলাটি নিয়ে না থাকেন তাহলে...    coRAC"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2ae59b1-b8b0-4b6f-9760-efa6455bd745\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>তোমাদের মেধা নেই বলে মডেল হতে পারছো না, নিজেদে...</td>\n",
              "      <td>coRAC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ওই ফকিরের কালো পোলা আমাদের সাথে খেতে পারবে না</td>\n",
              "      <td>coRAC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>আমি একজন বর্ণবাদী হয়ে জন্মেছি এবং আমি একজন বর...</td>\n",
              "      <td>coRAC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>দুশ্চরিত্রা নিগা আমাকে মিস করে</td>\n",
              "      <td>coRAC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>যদি আপনি সেই খুনের খেলাটি নিয়ে না থাকেন তাহলে...</td>\n",
              "      <td>coRAC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2ae59b1-b8b0-4b6f-9760-efa6455bd745')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2ae59b1-b8b0-4b6f-9760-efa6455bd745 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2ae59b1-b8b0-4b6f-9760-efa6455bd745');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import pandas as pd\n",
        "datapath = 'https://raw.githubusercontent.com/alanherprovat/Confedential-Dataset/main/niloythesis.csv'\n",
        "# datapath = 'https://raw.githubusercontent.com/alanherprovat/Confedential-Dataset/main/niloy2.csv'\n",
        "df = pd.read_csv(datapath)\n",
        "df = df.dropna(subset=['Category'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "zldJxdKb3Utg",
        "outputId": "8807cff7-3768-4851-e57b-7ab039d95862"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Category'>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df.groupby(['Category']).size().plot.bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQD21kvz3dTy",
        "outputId": "5b1c350b-bb75-4e71-b118-1ddfd358c437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEjWE5fr5ZRJ",
        "outputId": "500435df-27f8-4941-cb27-15b63736baa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,   938, 37376, 51003, 39893, 30806,   969, 42620, 19910,   102]])\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "example_text = 'আমি তাকে মেরে ফেলবো'\n",
        "bert_input = tokenizer(example_text,padding='max_length', max_length = 10,\n",
        "                       truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "print(bert_input['input_ids'])\n",
        "print(bert_input['token_type_ids'])\n",
        "print(bert_input['attention_mask'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ysE6B8l5uts",
        "outputId": "3abe664d-bf73-443d-df23-b1bcf6f37aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] আমি তাকে মেরে ফেলব [SEP]\n"
          ]
        }
      ],
      "source": [
        "example_text = tokenizer.decode(bert_input.input_ids[0])\n",
        "\n",
        "print(example_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6BqYbmS6BuA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "labels = {'coRAC':0,\n",
        "          'geoRAC':1,\n",
        "          'isRAC':2,\n",
        "          }\n",
        "# labels = {'ranoAG':0,\n",
        "#           'raAG':1,\n",
        "#           }\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "        self.labels = [labels[label.strip()] for label in df['Category']]\n",
        "        # self.labels = [labels[label] for label in df['Category']]\n",
        "        self.texts = [tokenizer(text,\n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['Text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAsy_MBn6Qpr",
        "outputId": "b50f88f9-dd3d-4c05-8e97-93bdf024535a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2612 326 327\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(112)\n",
        "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),\n",
        "                                     [int(.8*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(df_train),len(df_val), len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS0EnkBK6XyH"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 5)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "JGxxpbUt63_m",
        "outputId": "8f50090d-30fa-479b-c39f-860d169873c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 1306/1306 [05:06<00:00,  4.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss:  0.412                 | Train Accuracy:  0.744                 | Val Loss:  0.154                 | Val Accuracy:  0.936\n",
            "Test Precision: 0.9696 | Test Recall: 0.9694 | Test F1 Score: 0.9694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1306/1306 [05:05<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss:  0.096                 | Train Accuracy:  0.961                 | Val Loss:  0.077                 | Val Accuracy:  0.960\n",
            "Test Precision: 0.9606 | Test Recall: 0.9602 | Test F1 Score: 0.9603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1306/1306 [05:04<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss:  0.046                 | Train Accuracy:  0.984                 | Val Loss:  0.059                 | Val Accuracy:  0.966\n",
            "Test Precision: 0.9697 | Test Recall: 0.9694 | Test F1 Score: 0.9695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1306/1306 [05:05<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss:  0.028                 | Train Accuracy:  0.990                 | Val Loss:  0.066                 | Val Accuracy:  0.966\n",
            "Test Precision: 0.9762 | Test Recall: 0.9755 | Test F1 Score: 0.9755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1306/1306 [05:05<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss:  0.014                 | Train Accuracy:  0.997                 | Val Loss:  0.058                 | Val Accuracy:  0.966\n",
            "Test Precision: 0.9759 | Test Recall: 0.9755 | Test F1 Score: 0.9755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1306/1306 [05:05<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 6 | Train Loss:  0.010                 | Train Accuracy:  0.996                 | Val Loss:  0.068                 | Val Accuracy:  0.966\n",
            "Test Precision: 0.9486 | Test Recall: 0.9480 | Test F1 Score: 0.9480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1306/1306 [05:05<00:00,  4.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 7 | Train Loss:  0.005                 | Train Accuracy:  0.999                 | Val Loss:  0.078                 | Val Accuracy:  0.966\n",
            "Test Precision: 0.9734 | Test Recall: 0.9725 | Test F1 Score: 0.9725\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom torch.optim import Adam\\nfrom tqdm import tqdm\\nfrom sklearn.metrics import precision_recall_fscore_support\\n\\ndef train(model, train_data, val_data, test_data, learning_rate, epochs):\\n\\n    # create dataloaders for training, validation, and test sets\\n    train, val ,test= Dataset(train_data), Dataset(val_data),Dataset(test_data)\\n    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\\n    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\\n\\n\\n\\n    use_cuda = torch.cuda.is_available()\\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\\n\\n    # create optimizer and loss function\\n    criterion = nn.CrossEntropyLoss()\\n    optimizer = Adam(model.parameters(), lr=learning_rate)\\n\\n    for epoch_num in range(epochs):\\n\\n        # training loop\\n         for epoch_num in range(epochs):\\n\\n            total_acc_train = 0\\n            total_loss_train = 0\\n\\n            for train_input, train_label in tqdm(train_dataloader):\\n\\n                train_label = train_label.to(device)\\n                mask = train_input[\\'attention_mask\\'].to(device)\\n                input_id = train_input[\\'input_ids\\'].squeeze(1).to(device)\\n\\n                output = model(input_id, mask)\\n                \\n                batch_loss = criterion(output, train_label.long())\\n                total_loss_train += batch_loss.item()\\n                \\n                acc = (output.argmax(dim=1) == train_label).sum().item()\\n                total_acc_train += acc\\n\\n                model.zero_grad()\\n                batch_loss.backward()\\n                optimizer.step()\\n            \\n            total_acc_val = 0\\n            total_loss_val = 0\\n\\n            with torch.no_grad():\\n\\n                for val_input, val_label in val_dataloader:\\n\\n                    val_label = val_label.to(device)\\n                    mask = val_input[\\'attention_mask\\'].to(device)\\n                    input_id = val_input[\\'input_ids\\'].squeeze(1).to(device)\\n\\n                    output = model(input_id, mask)\\n\\n                    batch_loss = criterion(output, val_label.long())\\n                    total_loss_val += batch_loss.item()\\n                    \\n                    acc = (output.argmax(dim=1) == val_label).sum().item()\\n                    total_acc_val += acc\\n\\n        # test loop\\n        model.eval()\\n        test_labels = []\\n        test_preds = []\\n        with torch.no_grad():\\n            for test_input, test_label in test_dataloader:\\n                test_labels += test_label.tolist()\\n                test_label = test_label.to(device)\\n                mask = test_input[\\'attention_mask\\'].to(device)\\n                input_id = test_input[\\'input_ids\\'].squeeze(1).to(device)\\n                output = model(input_id, mask)\\n                preds = output.argmax(dim=1).tolist()\\n                test_preds += preds\\n        precision, recall, f1_score, _ = precision_recall_fscore_support(test_labels, test_preds, average=\\'weighted\\')\\n        print(f\\'Test Precision: {precision:.4f} | Test Recall: {recall:.4f} | Test F1 Score: {f1_score:.4f}\\')\\n\\n        # update model parameters\\n        \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def train(model, train_data, val_data, test_data,learning_rate, epochs):\n",
        "    test = Dataset(test_data)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "\n",
        "                batch_loss = criterion(output, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "\n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label.long())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "\n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "\n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "            model.eval()\n",
        "            test_labels = []\n",
        "            test_preds = []\n",
        "            with torch.no_grad():\n",
        "                for test_input, test_label in test_dataloader:\n",
        "                    test_labels += test_label.tolist()\n",
        "                    test_label = test_label.to(device)\n",
        "                    mask = test_input['attention_mask'].to(device)\n",
        "                    input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "                    output = model(input_id, mask)\n",
        "                    preds = output.argmax(dim=1).tolist()\n",
        "                    test_preds += preds\n",
        "            precision, recall, f1_score, _ = precision_recall_fscore_support(test_labels, test_preds, average='weighted')\n",
        "            print(f'Test Precision: {precision:.4f} | Test Recall: {recall:.4f} | Test F1 Score: {f1_score:.4f}')\n",
        "\n",
        "\n",
        "EPOCHS = 7\n",
        "model = BertClassifier()\n",
        "LR = 1e-6\n",
        "\n",
        "train(model, df_train, df_val,df_test ,LR, EPOCHS)\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def train(model, train_data, val_data, test_data, learning_rate, epochs):\n",
        "\n",
        "    # create dataloaders for training, validation, and test sets\n",
        "    train, val ,test= Dataset(train_data), Dataset(val_data),Dataset(test_data)\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    # create optimizer and loss function\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "        # training loop\n",
        "         for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "\n",
        "                batch_loss = criterion(output, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "\n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label.long())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "\n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "\n",
        "        # test loop\n",
        "        model.eval()\n",
        "        test_labels = []\n",
        "        test_preds = []\n",
        "        with torch.no_grad():\n",
        "            for test_input, test_label in test_dataloader:\n",
        "                test_labels += test_label.tolist()\n",
        "                test_label = test_label.to(device)\n",
        "                mask = test_input['attention_mask'].to(device)\n",
        "                input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "                output = model(input_id, mask)\n",
        "                preds = output.argmax(dim=1).tolist()\n",
        "                test_preds += preds\n",
        "        precision, recall, f1_score, _ = precision_recall_fscore_support(test_labels, test_preds, average='weighted')\n",
        "        print(f'Test Precision: {precision:.4f} | Test Recall: {recall:.4f} | Test F1 Score: {f1_score:.4f}')\n",
        "\n",
        "        # update model parameters\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBveyhtnEsKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd81121-5823-4660-c056-a849d8e937e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.972\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, test_data):\n",
        "\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "\n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "\n",
        "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "              total_acc_test += acc\n",
        "\n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
        "\n",
        "evaluate(model, df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-6ztgXD2M_z"
      },
      "source": [
        "#Confusion Matrix\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}